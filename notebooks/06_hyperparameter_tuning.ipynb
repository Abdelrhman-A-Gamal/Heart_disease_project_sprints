{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c73b1f8",
   "metadata": {},
   "source": [
    "Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c366844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded reduced_data shape: (297, 12)\n",
      "Loaded y shape: (297,)\n",
      "first 5 rows in reduced data:\n",
      "    thalach   oldpeak  thal_7.0       age  cp_4  trestbps      chol  exang_1  \\\n",
      "0  0.603053  0.370968         0  0.708333     0  0.481132  0.244292        0   \n",
      "1  0.282443  0.241935         0  0.791667     1  0.622642  0.365297        1   \n",
      "2  0.442748  0.419355         1  0.791667     1  0.245283  0.235160        1   \n",
      "3  0.885496  0.564516         0  0.166667     0  0.339623  0.283105        0   \n",
      "4  0.770992  0.225806         0  0.250000     0  0.339623  0.178082        0   \n",
      "\n",
      "   sex_1  slope_2  ca_1.0  cp_3  \n",
      "0      1        0       0     0  \n",
      "1      1        1       0     0  \n",
      "2      1        1       0     0  \n",
      "3      1        0       0     1  \n",
      "4      0        0       0     0  \n",
      "x_train shape: (237, 12)\n",
      "y_train shaoe: (237,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,RandomizedSearchCV\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score,precision_score,f1_score,recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#recover data\n",
    "input_data_path = '../data_through_notes/' # Relative path to data folder from notebooks folder\n",
    "reduced_df = pd.read_csv(os.path.join(input_data_path, 'reduced_data.csv'))\n",
    "y = pd.read_csv(os.path.join(input_data_path, 'y_processed.csv'))\n",
    "y=y.iloc[:,0]\n",
    "print(\"Loaded reduced_data shape:\", reduced_df.shape)\n",
    "print(\"Loaded y shape:\", y.shape)\n",
    "print('first 5 rows in reduced data:')\n",
    "print(reduced_df.head())\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(reduced_df,y,test_size=0.2,random_state=42)\n",
    "print(f'x_train shape: {x_train.shape}')\n",
    "print(f'y_train shaoe: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c636c8",
   "metadata": {},
   "source": [
    "Choosing Hyperparameters using GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af5e7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Gridsearch------\n",
      " \n",
      " \n",
      "\n",
      "------Logestic Regression------\n",
      "Tuned Logistic Regression Parameters: {'C': np.float64(0.4393970560760795)}\n",
      "Best score is 0.8141843971631205\n",
      "Accuracy Score with optimal parameter(Logestic Regression): 0.8833\n",
      "\n",
      " \n",
      " ------Random Forest------\n",
      "Tuned Random forest parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best score is 0.8011524822695038\n",
      "Accuracy Score:0.8333\n",
      "Precision Score: 0.8182\n",
      "F1-score: 0.7826\n",
      "Recall Score: 0.7500\n"
     ]
    }
   ],
   "source": [
    "print('------Gridsearch------\\n \\n \\n')\n",
    "#------Logestic Regression------\n",
    "c_space =np.logspace(-5,8,15)\n",
    "param_grid={\n",
    "    'C' :c_space\n",
    "}\n",
    "LogisticRegression_model=LogisticRegression()\n",
    "LogisticRegression_CV=GridSearchCV(LogisticRegression_model,param_grid,cv=5)\n",
    "LogisticRegression_CV.fit(x_train,y_train)\n",
    "print(f'------Logestic Regression------')\n",
    "print(f\"Tuned Logistic Regression Parameters: {LogisticRegression_CV.best_params_}\")\n",
    "print(\"Best score is {}\".format(LogisticRegression_CV.best_score_))\n",
    "\n",
    "#Using hyper parameter\n",
    "logreg_optimal=LogisticRegression(C=0.4393970560760795,max_iter=100)\n",
    "logreg_optimal.fit(x_train,y_train) \n",
    "y_logestic_predict=logreg_optimal.predict(x_test)\n",
    "print(f'Accuracy Score with optimal parameter(Logestic Regression): {accuracy_score(y_test,y_logestic_predict):.4f}')\n",
    "\n",
    "#------Random Forst------\n",
    "RF_params={\n",
    "    'n_estimators': [100, 200, 300], #https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "RandomForestClassifier_model=RandomForestClassifier(random_state=42)\n",
    "RandomForestClassifier_CV=GridSearchCV(RandomForestClassifier_model,RF_params,cv=5)\n",
    "RandomForestClassifier_CV.fit(x_train,y_train)\n",
    "print('\\n \\n ------Random Forest------')\n",
    "print(f'Tuned Random forest parameters: {RandomForestClassifier_CV.best_params_}')\n",
    "print(f'Best score is {RandomForestClassifier_CV.best_score_}')\n",
    "\n",
    "#using hyper parameter\n",
    "best_RF_model=RandomForestClassifier_CV.best_estimator_\n",
    "y_RF_predict=best_RF_model.predict(x_test)\n",
    "accuracy_grid=accuracy_score(y_test,y_RF_predict)\n",
    "percision_grid=precision_score(y_test,y_RF_predict)\n",
    "F1_grid=f1_score(y_test,y_RF_predict)\n",
    "Recall_grid=recall_score(y_test,y_RF_predict)\n",
    "print(f'Accuracy Score:{accuracy_grid:.4f}')\n",
    "print(f'Precision Score: {percision_grid:.4f}')\n",
    "print(f'F1-score: {F1_grid:.4f}')\n",
    "print(f'Recall Score: {Recall_grid:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52575894",
   "metadata": {},
   "source": [
    "Chossing hyperparameter using randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2edcfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Randomized serch------\n",
      " \n",
      " \n",
      "\n",
      "------Logestic Regression------\n",
      "Tuned Logistic Regression Parameters: {'C': np.float64(0.4393970560760795)}\n",
      "Best score is 0.8416949152542372\n",
      "Accuracy Score with optimal parameter(Logestic Regression): 0.8833\n",
      "\n",
      " \n",
      " ------Random Forest------\n",
      "Tuned Random forest parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': None, 'criterion': 'gini'}\n",
      "Best score is 0.8011524822695038\n",
      "Accuracy Score:0.8333\n",
      "Precision Score: 0.8182\n",
      "F1-score: 0.7826\n",
      "Recall Score: 0.7500\n"
     ]
    }
   ],
   "source": [
    "print('------Randomized serch------\\n \\n \\n')\n",
    "\n",
    "#------logestic Regression------\n",
    "c_space =np.logspace(-5,8,15)\n",
    "param_grid={\n",
    "    'C' :c_space\n",
    "}\n",
    "LogisticRegression_model=LogisticRegression()\n",
    "LogisticRegression_CV=RandomizedSearchCV(LogisticRegression_model,param_grid,cv=5)\n",
    "LogisticRegression_CV.fit(reduced_df,y)\n",
    "print(f'------Logestic Regression------')\n",
    "print(f\"Tuned Logistic Regression Parameters: {LogisticRegression_CV.best_params_}\")\n",
    "print(\"Best score is {}\".format(LogisticRegression_CV.best_score_))\n",
    "\n",
    "#Using hyper parameter\n",
    "logreg_optimal=LogisticRegression(C=0.4393970560760795,max_iter=100)\n",
    "logreg_optimal.fit(x_train,y_train) \n",
    "y_logestic_predict=logreg_optimal.predict(x_test)\n",
    "print(f'Accuracy Score with optimal parameter(Logestic Regression): {accuracy_score(y_test,y_logestic_predict):.4f}')\n",
    "\n",
    "\n",
    "#------Random Forst------\n",
    "RF_params={\n",
    "    'n_estimators': [100, 200, 300], #https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "RandomForestClassifier_model=RandomForestClassifier(random_state=42)\n",
    "RandomForestClassifier_CV_random=RandomizedSearchCV(RandomForestClassifier_model,RF_params,cv=5)\n",
    "RandomForestClassifier_CV_random.fit(x_train,y_train)\n",
    "print('\\n \\n ------Random Forest------')\n",
    "print(f'Tuned Random forest parameters: {RandomForestClassifier_CV_random.best_params_}')\n",
    "print(f'Best score is {RandomForestClassifier_CV_random.best_score_}')\n",
    "\n",
    "#using hyper parameter\n",
    "best_RF_model_random=RandomForestClassifier_CV_random.best_estimator_\n",
    "y_RF_predict_random=best_RF_model_random.predict(x_test)\n",
    "accuracy_random=accuracy_score(y_test,y_RF_predict_random)\n",
    "percision_random=precision_score(y_test,y_RF_predict_random)\n",
    "F1_random=f1_score(y_test,y_RF_predict_random)\n",
    "Recall_random=recall_score(y_test,y_RF_predict_random)\n",
    "print(f'Accuracy Score:{accuracy_random:.4f}')\n",
    "print(f'Precision Score: {percision_random:.4f}')\n",
    "print(f'F1-score: {F1_random:.4f}')\n",
    "print(f'Recall Score: {Recall_random:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add15e6",
   "metadata": {},
   "source": [
    "Choosing the best performance model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61b32f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary of Optimized Model Performance ---\n",
      "Best Optimization Method: GridSearchCV\n",
      "Accuracy: 0.8333\n",
      "Precision: 0.8182\n",
      "Recall: 0.7500\n",
      "F1-Score: 0.7826\n"
     ]
    }
   ],
   "source": [
    "if RandomForestClassifier_CV.best_score_ >= RandomForestClassifier_CV_random.best_score_:\n",
    "    final_optimized_model = best_RF_model\n",
    "    optimized_model_performance = {\n",
    "        'Method': 'GridSearchCV',\n",
    "        'Accuracy': accuracy_grid,\n",
    "        'Precision': percision_grid,\n",
    "        'Recall': Recall_grid,\n",
    "        'F1-Score': F1_grid,\n",
    "    }\n",
    "else:\n",
    "    final_optimized_model = best_RF_model_random\n",
    "    optimized_model_performance = {\n",
    "        'Method': 'RandomizedSearchCV',\n",
    "        'Accuracy': accuracy_random,\n",
    "        'Precision': percision_grid,\n",
    "        'Recall': Recall_random,\n",
    "        'F1-Score': F1_random,\n",
    "    }\n",
    "\n",
    "print(\"\\n--- Summary of Optimized Model Performance ---\")\n",
    "print(f\"Best Optimization Method: {optimized_model_performance['Method']}\")\n",
    "print(f\"Accuracy: {optimized_model_performance['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {optimized_model_performance['Precision']:.4f}\")\n",
    "print(f\"Recall: {optimized_model_performance['Recall']:.4f}\")\n",
    "print(f\"F1-Score: {optimized_model_performance['F1-Score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07594b61",
   "metadata": {},
   "source": [
    "Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eb0b310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Export ---\n",
      "Final optimized model saved to: ../models/best_RF_heart_disease_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- Model Export ---\n",
    "print(\"\\n--- Model Export ---\")\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Define the path to save the model\n",
    "model_save_path = '../models/'\n",
    "os.makedirs(model_save_path, exist_ok=True) # Create the directory if it doesn't exist\n",
    "\n",
    "# The final_optimized_model was chosen based on best test AUC\n",
    "# This will save the best model (which was RandomForest_Grid in your last run)\n",
    "model_filename = os.path.join(model_save_path, 'best_RF_heart_disease_model.joblib')\n",
    "\n",
    "joblib.dump(final_optimized_model, model_filename)\n",
    "\n",
    "print(f\"Final optimized model saved to: {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
